import json
import argparse
import random
import os
import time


def clear_screen():
    """Clears the terminal screen."""
    os.system('cls' if os.name == 'nt' else 'clear')

def main():
    parser = argparse.ArgumentParser(
        description="Interactively review and select high-quality queries for translation.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--input-file", 
        default="witcher_benchmark_dataset_final_v7.json",
        help="The full benchmark JSON file generated by the DatasetGenerator."
    )
    parser.add_argument(
        "--output-file", 
        default="curated_queries_for_translation.json",
        help="The new JSON file to save the approved queries to."
    )
    parser.add_argument(
        "--num-to-review", 
        type=int, 
        default=100,
        help="The number of random queries to present for review."
    )
    
    args = parser.parse_args()

    # --- 1. Load the full dataset ---
    # print(f"Loading full dataset from {args.input-file}...")
    try:
        with open(args.input_file, 'r') as f:
            all_queries = json.load(f)
    except FileNotFoundError:
        print(f"Error: Input file not found at '{args.input_file}'")
        return

    # --- 2. Create a random sample for review ---
    if len(all_queries) < args.num_to_review:
        print(f"Warning: Requested to review {args.num_to_review}, but only {len(all_queries)} queries are available. Reviewing all.")
        num_to_review = len(all_queries)
    else:
        num_to_review = args.num_to_review
        
    random.shuffle(all_queries)
    queries_to_review = all_queries[:num_to_review]

    print(f"Loaded {len(all_queries)} queries. Presenting {len(queries_to_review)} for your review.")
    input("Press Enter to begin the review process...")

    # --- 3. The Interactive Review Loop ---
    approved_queries = []
    quit_flag = False

    for i, item in enumerate(queries_to_review):
        clear_screen()
        print(f"--- Reviewing Query {i + 1} of {len(queries_to_review)} ---")
        print(f"Template ID: {item.get('template_id', 'N/A')}\n")
        print("Generated Natural Language Question:")
        print(f"  > {item.get('natural_language_question', 'N/A')}\n")
        print("Original SPARQL Query:")
        print(f"  {item.get('query', 'N/A')}")
        print("--------------------------------------------------")

        while True:
            choice = input("Approve this query for translation? (y/n/q to quit): ").lower().strip()
            if choice in ['y', 'yes']:
                approved_queries.append(item)
                print("  -> Approved.")
                time.sleep(0.5)
                break
            elif choice in ['n', 'no']:
                print("  -> Skipped.")
                time.sleep(0.5)
                break
            elif choice in ['q', 'quit']:
                print("  -> Quitting review process.")
                quit_flag = True
                break
            else:
                print("  Invalid input. Please enter 'y', 'n', or 'q'.")
        
        if quit_flag:
            break

    # --- 4. Save the curated list ---
    clear_screen()
    print("--- Review Complete ---")
    if not approved_queries:
        print("No queries were approved. No output file will be created.")
    else:
        print(f"You approved {len(approved_queries)} out of {i + 1} reviewed queries.")
        print(f"Saving the curated list to {args.output_file}...")
        with open(args.output_file, 'w') as f:
            json.dump(approved_queries, f, indent=2)
        print("Save complete.")

if __name__ == "__main__":
    main()